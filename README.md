# getting_deepfakes
we’ll generate a deepfake video of a group member  speaking like a random man from the internet. We’ll use a machine learning model developed by Aliaksandr Siarohin and others in their paper “First Order Motion Model for Image Animation.” The model is special because it learns the movements from an input video and uses these movements to animate a picture. This makes it more efficient than earlier techniques that required users to supply
the model with multiple images.

we use google collabs attached above with our requires video and image

Download the model weights (vox-adv-cpk.pth.tar) https://drive.google.com/file/d/15CpncEhYB8jBItzd78hR3bmKnLR_E7Et/view?usp=sharing

Explore the deepfake
